{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block allows us to import from the benchmark folder,\n",
    "# as if it was a package installed using pip\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import datasets, methods, models\n",
    "from benchmark.sensitivity_n import sensitivity_n\n",
    "import itertools\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General parameters\n",
    "BATCH_SIZE = 16\n",
    "DATA_ROOT = \"../data\"\n",
    "USE_LOGITS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR10 parameters\n",
    "dataset = datasets.Cifar(batch_size=BATCH_SIZE, data_location=os.path.join(DATA_ROOT, \"CIFAR10\"), download=False, shuffle=False, version=\"cifar10\")\n",
    "model = models.CifarResnet(version=\"resnet32\", params_loc=\"../data/models/cifar10_resnet32.pth\", num_classes=10, output_logits=USE_LOGITS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST parameters\n",
    "dataset = datasets.MNIST(batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"MNIST\"\n",
    "DOWNLOAD_DATASET = False\n",
    "MODEL = \"CNN\"\n",
    "BATCH_SIZE = 64\n",
    "N_BATCHES = 2\n",
    "N_SUBSETS = 100\n",
    "#MASK_RANGE = range(1, 1000, 100)\n",
    "MASK_RANGE = range(1, 700, 50)\n",
    "METHODS = [\"GuidedGradCAM\", \"Gradient\", \"InputXGradient\", \"IntegratedGradients\",\n",
    "           \"GuidedBackprop\", \"Deconvolution\", \"Random\"]\n",
    "\n",
    "# TODO instead of having this global dictionary, expose getter methods that do the necessary validations\n",
    "dataset_constructor = DATASET_MODELS[DATASET][\"constructor\"]\n",
    "model_constructor = DATASET_MODELS[DATASET][\"models\"][MODEL]\n",
    "method_constructors = get_method_constructors(METHODS)\n",
    "\n",
    "all_kwargs = {\"Occlusion\": {\"sliding_window_shapes\": (1, 1, 1)}}\n",
    "\n",
    "model = model_constructor(output_logits=True)\n",
    "dataset = dataset_constructor(batch_size=BATCH_SIZE, shuffle=False, download=DOWNLOAD_DATASET,\n",
    "                              data_location=\"../../data\")\n",
    "\n",
    "x = np.array(MASK_RANGE)\n",
    "methods = {m_name: method_constructors[m_name](model, normalize=True, **all_kwargs.get(m_name, {})) for m_name in METHODS}\n",
    "sensitivity_n(itertools.islice(dataset.get_test_loader(), N_BATCHES), lambda x: model.predict(x).detach().numpy(),\n",
    "              methods, list(MASK_RANGE), mask_value=-0.4242)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
